{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# default_exp cellular_automata"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# module name here\n",
    "\n",
    "> API details."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#hide\n",
    "from nbdev.showdoc import *"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We use cellular automata to synthesize covid19 lesions   \n",
    "initial code from: https://github.com/Mayukhdeb/differentiable-morphogenesis   \n",
    "based on: https://distill.pub/2020/growing-ca/   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "import cv2 \n",
    "import torch\n",
    "import numpy as np\n",
    "import torch.nn as nn \n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "import matplotlib.pyplot as plt \n",
    "from IPython.display import Image, HTML, clear_output\n",
    "import matplotlib\n",
    "import io\n",
    "import sys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "def to_rgb(img, channel=1):\n",
    "    '''return visible channel'''\n",
    "    # rgb, a = img[:,:,:1], img[:,:,1:2]\n",
    "    rgb, a = img[:,:,:channel], img[:,:,channel:channel+1]\n",
    "    return 1.0-a+rgb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "def correct_label_in_plot(model):\n",
    "    '''get a string with the network architecture to print in the figure'''\n",
    "    # https://www.kite.com/python/answers/how-to-redirect-print-output-to-a-variable-in-python\n",
    "    old_stdout = sys.stdout\n",
    "    new_stdout = io.StringIO()\n",
    "    sys.stdout = new_stdout\n",
    "    print(model);\n",
    "    output = new_stdout.getvalue()\n",
    "    sys.stdout = old_stdout\n",
    "\n",
    "    model_str = [i.split(', k')[0] for i in output.split('\\n')]\n",
    "    model_str_layers = [i.split(':')[-1] for i in model_str[2:-3]]\n",
    "    model_str = [model_str[0]]+model_str_layers\n",
    "    model_str = str(model_str).replace(\"', '\",'\\n')\n",
    "    return model_str"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "def create_sobel_and_identity(device='cuda'):\n",
    "  ident = torch.tensor([[0.0,0.0,0.0],[0.0,1.0,0.0],[0.0,0.0,0.0]]).to(device)\n",
    "  sobel_x = (torch.tensor([[-1.0,0.0,1.0],[-2.0,0.0,2.0],[-1.0,0.0,1.0]])/8.0).to(device)\n",
    "  lap = (torch.tensor([[1.0,2.0,1.0],[2.0,-12,2.0],[1.0,2.0,1.0]])/16.0).to(device)\n",
    "  return ident, sobel_x, lap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "class ca_model_perception(nn.Module):\n",
    "    def __init__(self, checkpoint = None, seq_layers = None, device = 'cuda'):\n",
    "        '''\n",
    "        Kind of a modular class for a CA model\n",
    "        args:\n",
    "            checkpoint = 'path/to/model.pt'\n",
    "            seq_layers = nn.Sequential(your, pytorch, layers)\n",
    "            device = 'cuda' or 'cpu'\n",
    "        '''\n",
    "        super(ca_model_perception, self).__init__()\n",
    "\n",
    "        if seq_layers is not None:\n",
    "            self.model = seq_layers\n",
    "        else:\n",
    "            self.model = nn.Sequential(\n",
    "                nn.Conv2d(64, 256, kernel_size = 3,padding =1,  bias = True),  \n",
    "                nn.ReLU(),\n",
    "                nn.Conv2d(256, 256, kernel_size = 3,padding =1,  bias = True),  \n",
    "                nn.ReLU(),\n",
    "                nn.Conv2d(256, 16, kernel_size =  1, bias = True),\n",
    "            )\n",
    "            \n",
    "        '''\n",
    "        initial condition for \"do nothing\" behaviour:\n",
    "            * all biases should be zero\n",
    "            * the weights of the last layer should be zero\n",
    "        '''\n",
    "        for l in range(len(self.model)):\n",
    "            if isinstance(self.model[l], nn.Conv2d):\n",
    "                self.model[l].bias.data.fill_(0)\n",
    "                if l == len(self.model) -1:\n",
    "                    self.model[l].weight.data.fill_(0)\n",
    "\n",
    "        if checkpoint is not None:\n",
    "            self.load_state_dict(torch.load(checkpoint))\n",
    "\n",
    "        self.to(device= device)\n",
    "    \n",
    "    def perchannel_conv(self, x, filters):\n",
    "        '''filters: [filter_n, h, w]'''\n",
    "        b, ch, h, w = x.shape\n",
    "        y = x.reshape(b*ch, 1, h, w)\n",
    "        y = torch.nn.functional.pad(y, [1, 1, 1, 1], 'circular')\n",
    "        y = torch.nn.functional.conv2d(y, filters[:,None])\n",
    "        return y.reshape(b, -1, h, w)\n",
    "\n",
    "    def perception(self, x):\n",
    "        filters = torch.stack([ident, sobel_x, sobel_x.T, lap])\n",
    "        return self.perchannel_conv(x, filters)\n",
    "        \n",
    "    def normalize_grads(self):\n",
    "        '''\n",
    "        gradient normalization for constant step size and to avoid spikes \n",
    "        '''\n",
    "        for p in self.parameters():\n",
    "            p.grad.data = p.grad.data/(p.grad.data.norm()+1e-8)    \n",
    "            \n",
    "            \n",
    "    def get_alive_mask(self, x):\n",
    "        '''\n",
    "        looks for cells that have values over 0.1, \n",
    "        and allows only their adjacent cells to participate in growth\n",
    "        '''\n",
    "        alpha = x[:,1:2,:,:]\n",
    "        pooled = (F.max_pool2d(alpha, 3,1, padding =1 ) > 0.1).float()\n",
    "        return pooled\n",
    "    \n",
    "    def train_step(self, seed, target, target_loss_func, iters, current_epoch = 1000, masked_loss=False):\n",
    "        '''\n",
    "        a single training step for the model,\n",
    "        feel free to play around with different loss functions like L1 loss \n",
    "\n",
    "        the loss is calculated for only the first 4 channels of the output\n",
    "        '''\n",
    "        x = seed \n",
    "        for i in range(iters):\n",
    "            x, alive_mask =  self.forward(x,i, current_epoch)\n",
    "\n",
    "        # print(x[:,:4, :,:].shape, target.shape)\n",
    "        # batch_mean_rmse_per_pixel = torch.mean(torch.sqrt((x[:,:1, :,:] - target)**2),dim=0)\n",
    "        batch_mean_rmse_per_pixel = torch.mean(torch.sqrt((x[:,0, :,:] - target[:,0,:,:])**2),dim=0)\n",
    "\n",
    "        if masked_loss == True:\n",
    "            alive_mask_dilated = (F.max_pool2d(alive_mask[0], 3,1, padding =1 ) > 0.1).float()\n",
    "            # alive_mask_dilated = torch.from_numpy(binary_closing(alive_mask[0].cpu().numpy() > 0.1)).float().to('cuda')\n",
    "            target_loss  =  target_loss_func(x[:,:1, :,:] * alive_mask_dilated, target * alive_mask_dilated)  \n",
    "        else:\n",
    "            target_loss  =  target_loss_func(x[:,:2, :,:] * target_batch[:,1:,...], target * target_batch[:,1:,...]) # used to synthesize almost all nodules \n",
    "\n",
    "\n",
    "\n",
    "        loss = target_loss \n",
    "            \n",
    "        return loss, x, alive_mask.cpu().numpy() #batch_mean_rmse_per_pixel.detach().cpu().numpy()\n",
    "\n",
    "    def forward(self, x, i, current_epoch):\n",
    "        '''\n",
    "        nice little forward function for the model\n",
    "        1. fetches an alive mask \n",
    "        2. generates another random mask of 0's and 1's \n",
    "        3. updates the input \n",
    "        4. applies alive mask \n",
    "        '''\n",
    "        if current_epoch < 100: \n",
    "          alive_mask = self.get_alive_mask(x)\n",
    "        else:\n",
    "          if i % 3 == 0:\n",
    "            alive_mask = self.get_alive_mask(x)\n",
    "          else:\n",
    "            # alive_mask = self.get_alive_mask(x)\n",
    "            alive_mask = (x[:,1:2,:,:] > 0.1).float()\n",
    "        mask = torch.clamp(torch.round(torch.rand_like(x[:,:1,:,:])) , 0,1)        \n",
    "        y = self.perception(x)\n",
    "        out = x + self.model(y)*mask  \n",
    "        out *= alive_mask\n",
    "        \n",
    "        return out, alive_mask"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
