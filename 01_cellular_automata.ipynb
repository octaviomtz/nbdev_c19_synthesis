{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# default_exp cellular_automata"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# module name here\n",
    "\n",
    "> API details."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#hide\n",
    "from nbdev.showdoc import *"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We use cellular automata to synthesize covid19 lesions   \n",
    "initial code from: https://github.com/Mayukhdeb/differentiable-morphogenesis   \n",
    "based on: https://distill.pub/2020/growing-ca/   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "import cv2 \n",
    "import torch\n",
    "import numpy as np\n",
    "import torch.nn as nn \n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "import matplotlib.pyplot as plt \n",
    "from IPython.display import Image, HTML, clear_output\n",
    "import matplotlib\n",
    "import io\n",
    "import sys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# #export\n",
    "# import kornia\n",
    "# gradient_filter = kornia.filters.sobel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "def to_rgb(img, channel=1):\n",
    "    '''return visible channel'''\n",
    "    # rgb, a = img[:,:,:1], img[:,:,1:2]\n",
    "    rgb, a = img[:,:,:channel], img[:,:,channel:channel+1]\n",
    "    return 1.0-a+rgb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "def correct_label_in_plot(model):\n",
    "    '''get a string with the network architecture to print in the figure'''\n",
    "    # https://www.kite.com/python/answers/how-to-redirect-print-output-to-a-variable-in-python\n",
    "    old_stdout = sys.stdout\n",
    "    new_stdout = io.StringIO()\n",
    "    sys.stdout = new_stdout\n",
    "    print(model);\n",
    "    output = new_stdout.getvalue()\n",
    "    sys.stdout = old_stdout\n",
    "\n",
    "    model_str = [i.split(', k')[0] for i in output.split('\\n')]\n",
    "    model_str_layers = [i.split(':')[-1] for i in model_str[2:-3]]\n",
    "    model_str = [model_str[0]]+model_str_layers\n",
    "    model_str = str(model_str).replace(\"', '\",'\\n')\n",
    "    return model_str"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "def create_sobel_and_identity(device='cuda'):\n",
    "  ident = torch.tensor([[0.0,0.0,0.0],[0.0,1.0,0.0],[0.0,0.0,0.0]]).to(device)\n",
    "  sobel_x = (torch.tensor([[-1.0,0.0,1.0],[-2.0,0.0,2.0],[-1.0,0.0,1.0]])/8.0).to(device)\n",
    "  lap = (torch.tensor([[1.0,2.0,1.0],[2.0,-12,2.0],[1.0,2.0,1.0]])/16.0).to(device)\n",
    "  return ident, sobel_x, lap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "def prepare_seed(target, this_seed, device, num_channels = 16, pool_size = 1024):\n",
    "# prepare seed\n",
    "  height, width, _ = np.shape(target)\n",
    "  seed = np.zeros([1, height, width, num_channels], np.float32)\n",
    "  for i in range(num_channels-1):\n",
    "    seed[:,..., i+1] = this_seed\n",
    "  # Preparing the seed pool\n",
    "  seed_tensor = torch.tensor(seed).permute(0,-1,1,2).to(device)\n",
    "  seed_pool = torch.repeat_interleave(seed_tensor, repeats = pool_size, dim = 0)\n",
    "  return seed, seed_tensor, seed_pool"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "def epochs_in_inner_loop(i, inner_iter_aux=0, inner_iter=0, thresh_do_nothing=100, thresh_do_something=200, increase=10, inner_iter_max=100):\n",
    "  if i < thresh_do_nothing:\n",
    "    inner_iter = 100\n",
    "  elif i % thresh_do_something == 0: \n",
    "    inner_iter_aux = inner_iter_aux + increase\n",
    "    inner_iter = np.min([inner_iter_aux, inner_iter_max])\n",
    "  else:\n",
    "    inner_iter=inner_iter\n",
    "  return inner_iter, inner_iter_aux"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "class ca_model_baseline(nn.Module):\n",
    "    def __init__(self, checkpoint = None, seq_layers = None, device = 'cuda'):\n",
    "        '''\n",
    "        Kind of a modular class for a CA model\n",
    "        args:\n",
    "            checkpoint = 'path/to/model.pt'\n",
    "            seq_layers = nn.Sequential(your, pytorch, layers)\n",
    "            device = 'cuda' or 'cpu'\n",
    "        '''\n",
    "        super(ca_model_baseline, self).__init__()\n",
    "\n",
    "        self.ident = torch.tensor([[0.0,0.0,0.0],[0.0,1.0,0.0],[0.0,0.0,0.0]]).to(device)\n",
    "        self.sobel_x = (torch.tensor([[-1.0,0.0,1.0],[-2.0,0.0,2.0],[-1.0,0.0,1.0]])/8.0).to(device)\n",
    "        self.lap = (torch.tensor([[1.0,2.0,1.0],[2.0,-12,2.0],[1.0,2.0,1.0]])/16.0).to(device)\n",
    "        \n",
    "        if seq_layers is not None:\n",
    "            self.model = seq_layers\n",
    "        else:\n",
    "            self.model = nn.Sequential(\n",
    "                nn.Conv2d(64, 256, kernel_size = 3,padding =1,  bias = True),  \n",
    "                nn.ReLU(),\n",
    "                nn.Conv2d(256, 256, kernel_size = 3,padding =1,  bias = True),  \n",
    "                nn.ReLU(),\n",
    "                nn.Conv2d(256, 16, kernel_size =  1, bias = True),\n",
    "            )\n",
    "            \n",
    "        '''\n",
    "        initial condition for \"do nothing\" behaviour:\n",
    "            * all biases should be zero\n",
    "            * the weights of the last layer should be zero\n",
    "        '''\n",
    "        for l in range(len(self.model)):\n",
    "            if isinstance(self.model[l], nn.Conv2d):\n",
    "                self.model[l].bias.data.fill_(0)\n",
    "                if l == len(self.model) -1:\n",
    "                    self.model[l].weight.data.fill_(0)\n",
    "\n",
    "        if checkpoint is not None:\n",
    "            self.load_state_dict(torch.load(checkpoint))\n",
    "\n",
    "        self.to(device= device)\n",
    "    \n",
    "    def perchannel_conv(self, x, filters):\n",
    "        '''filters: [filter_n, h, w]'''\n",
    "        b, ch, h, w = x.shape\n",
    "        y = x.reshape(b*ch, 1, h, w)\n",
    "        y = torch.nn.functional.pad(y, [1, 1, 1, 1], 'circular')\n",
    "        y = torch.nn.functional.conv2d(y, filters[:,None])\n",
    "        return y.reshape(b, -1, h, w)\n",
    "\n",
    "    def perception(self, x):\n",
    "        filters = torch.stack([self.ident, self.sobel_x, self.sobel_x.T, self.lap])\n",
    "        return self.perchannel_conv(x, filters)\n",
    "        \n",
    "    def normalize_grads(self):\n",
    "        '''\n",
    "        gradient normalization for constant step size and to avoid spikes \n",
    "        '''\n",
    "        for p in self.parameters():\n",
    "            p.grad.data = p.grad.data/(p.grad.data.norm()+1e-8)    \n",
    "            \n",
    "            \n",
    "    def get_alive_mask(self, x):\n",
    "        '''\n",
    "        looks for cells that have values over 0.1, \n",
    "        and allows only their adjacent cells to participate in growth\n",
    "        '''\n",
    "        alpha = x[:,1:2,:,:]\n",
    "        pooled = (F.max_pool2d(alpha, 3,1, padding =1 ) > 0.1).float()\n",
    "        return pooled\n",
    "    \n",
    "    def train_step(self, seed, target, target_loss_func, epochs_inside, masked_loss=False):\n",
    "        '''\n",
    "        a single training step for the model,\n",
    "        feel free to play around with different loss functions like L1 loss \n",
    "\n",
    "        the loss is calculated for only the first 4 channels of the output\n",
    "        '''\n",
    "        x = seed \n",
    "        for i in range(epochs_inside):\n",
    "            x, alive_mask =  self.forward(x)\n",
    "\n",
    "        target_loss  =  target_loss_func(x[:,:2, :,:], target) # used to synthesize almost all nodules \n",
    "        loss = target_loss \n",
    "            \n",
    "        return loss, x, alive_mask.cpu().numpy() #batch_mean_rmse_per_pixel.detach().cpu().numpy()\n",
    "\n",
    "    def forward(self, x):\n",
    "        '''\n",
    "        nice little forward function for the model\n",
    "        1. fetches an alive mask \n",
    "        2. generates another random mask of 0's and 1's \n",
    "        3. updates the input \n",
    "        4. applies alive mask \n",
    "        '''\n",
    "        alive_mask = self.get_alive_mask(x)\n",
    "        mask = torch.clamp(torch.round(torch.rand_like(x[:,:1,:,:])) , 0,1)        \n",
    "        y = self.perception(x)\n",
    "        out = x + self.model(y)*mask  \n",
    "        out *= alive_mask\n",
    "        \n",
    "        return out, alive_mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "class ca_model_perception(nn.Module):\n",
    "    def __init__(self, checkpoint = None, seq_layers = None, device = 'cuda'):\n",
    "        '''\n",
    "        Kind of a modular class for a CA model\n",
    "        args:\n",
    "            checkpoint = 'path/to/model.pt'\n",
    "            seq_layers = nn.Sequential(your, pytorch, layers)\n",
    "            device = 'cuda' or 'cpu'\n",
    "        '''\n",
    "        super(ca_model_perception, self).__init__()\n",
    "\n",
    "        self.ident = torch.tensor([[0.0,0.0,0.0],[0.0,1.0,0.0],[0.0,0.0,0.0]]).to(device)\n",
    "        self.sobel_x = (torch.tensor([[-1.0,0.0,1.0],[-2.0,0.0,2.0],[-1.0,0.0,1.0]])/8.0).to(device)\n",
    "        self.lap = (torch.tensor([[1.0,2.0,1.0],[2.0,-12,2.0],[1.0,2.0,1.0]])/16.0).to(device)\n",
    "        \n",
    "        if seq_layers is not None:\n",
    "            self.model = seq_layers\n",
    "        else:\n",
    "            self.model = nn.Sequential(\n",
    "                nn.Conv2d(64, 256, kernel_size = 3,padding =1,  bias = True),  \n",
    "                nn.ReLU(),\n",
    "                nn.Conv2d(256, 256, kernel_size = 3,padding =1,  bias = True),  \n",
    "                nn.ReLU(),\n",
    "                nn.Conv2d(256, 16, kernel_size =  1, bias = True),\n",
    "            )\n",
    "            \n",
    "        '''\n",
    "        initial condition for \"do nothing\" behaviour:\n",
    "            * all biases should be zero\n",
    "            * the weights of the last layer should be zero\n",
    "        '''\n",
    "        for l in range(len(self.model)):\n",
    "            if isinstance(self.model[l], nn.Conv2d):\n",
    "                self.model[l].bias.data.fill_(0)\n",
    "                if l == len(self.model) -1:\n",
    "                    self.model[l].weight.data.fill_(0)\n",
    "\n",
    "        if checkpoint is not None:\n",
    "            self.load_state_dict(torch.load(checkpoint))\n",
    "\n",
    "        self.to(device= device)\n",
    "    \n",
    "    def perchannel_conv(self, x, filters):\n",
    "        '''filters: [filter_n, h, w]'''\n",
    "        b, ch, h, w = x.shape\n",
    "        y = x.reshape(b*ch, 1, h, w)\n",
    "        y = torch.nn.functional.pad(y, [1, 1, 1, 1], 'circular')\n",
    "        y = torch.nn.functional.conv2d(y, filters[:,None])\n",
    "        return y.reshape(b, -1, h, w)\n",
    "\n",
    "    def perception(self, x):\n",
    "        filters = torch.stack([self.ident, self.sobel_x, self.sobel_x.T, self.lap])\n",
    "        return self.perchannel_conv(x, filters)\n",
    "        \n",
    "    def normalize_grads(self):\n",
    "        '''\n",
    "        gradient normalization for constant step size and to avoid spikes \n",
    "        '''\n",
    "        for p in self.parameters():\n",
    "            p.grad.data = p.grad.data/(p.grad.data.norm()+1e-8)    \n",
    "            \n",
    "            \n",
    "    def get_alive_mask(self, x):\n",
    "        '''\n",
    "        looks for cells that have values over 0.1, \n",
    "        and allows only their adjacent cells to participate in growth\n",
    "        '''\n",
    "        alpha = x[:,1:2,:,:]\n",
    "        pooled = (F.max_pool2d(alpha, 3,1, padding =1 ) > 0.1).float()\n",
    "        return pooled\n",
    "    \n",
    "    def train_step(self, seed, target, target_loss_func, iters, current_epoch = 1000, masked_loss=False):\n",
    "        '''\n",
    "        a single training step for the model,\n",
    "        feel free to play around with different loss functions like L1 loss \n",
    "\n",
    "        the loss is calculated for only the first 4 channels of the output\n",
    "        '''\n",
    "        x = seed \n",
    "        for i in range(iters):\n",
    "            x, alive_mask =  self.forward(x,i, current_epoch)\n",
    "\n",
    "        # print(x[:,:4, :,:].shape, target.shape)\n",
    "        # batch_mean_rmse_per_pixel = torch.mean(torch.sqrt((x[:,:1, :,:] - target)**2),dim=0)\n",
    "        batch_mean_rmse_per_pixel = torch.mean(torch.sqrt((x[:,0, :,:] - target[:,0,:,:])**2),dim=0)\n",
    "\n",
    "        if masked_loss == True:\n",
    "            alive_mask_dilated = (F.max_pool2d(alive_mask[0], 3,1, padding =1 ) > 0.1).float()\n",
    "            # alive_mask_dilated = torch.from_numpy(binary_closing(alive_mask[0].cpu().numpy() > 0.1)).float().to('cuda')\n",
    "            target_loss  =  target_loss_func(x[:,:1, :,:] * alive_mask_dilated, target * alive_mask_dilated)  \n",
    "        else:\n",
    "            target_loss  =  target_loss_func(x[:,:2, :,:] * target[:,1:,...], target * target[:,1:,...]) # used to synthesize almost all nodules \n",
    "\n",
    "\n",
    "\n",
    "        loss = target_loss \n",
    "            \n",
    "        return loss, x, alive_mask.cpu().numpy() #batch_mean_rmse_per_pixel.detach().cpu().numpy()\n",
    "\n",
    "    def forward(self, x, i, current_epoch):\n",
    "        '''\n",
    "        nice little forward function for the model\n",
    "        1. fetches an alive mask \n",
    "        2. generates another random mask of 0's and 1's \n",
    "        3. updates the input \n",
    "        4. applies alive mask \n",
    "        '''\n",
    "        if current_epoch < 100: \n",
    "          alive_mask = self.get_alive_mask(x)\n",
    "        else:\n",
    "          if i % 3 == 0:\n",
    "            alive_mask = self.get_alive_mask(x)\n",
    "          else:\n",
    "            # alive_mask = self.get_alive_mask(x)\n",
    "            alive_mask = (x[:,1:2,:,:] > 0.1).float()\n",
    "        mask = torch.clamp(torch.round(torch.rand_like(x[:,:1,:,:])) , 0,1)        \n",
    "        y = self.perception(x)\n",
    "        out = x + self.model(y)*mask  \n",
    "        out *= alive_mask\n",
    "        \n",
    "        return out, alive_mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "def plot_loss_and_lesion_synthesis(losses, optimizer, model_str, i, loss, sample_size, out):\n",
    "  clear_output(True)\n",
    "  f, (ax0, ax1) = plt.subplots(2, 1, figsize=(12,10), gridspec_kw={'height_ratios': [4, 1]})\n",
    "  lr_info = f'\\nlr_init={optimizer.param_groups[0][\"initial_lr\"]:.1E}\\nlr_last={optimizer.param_groups[0][\"lr\"]:.1E}'\n",
    "  model_str_final = model_str+lr_info\n",
    "  ax0.plot(losses, label=model_str_final)\n",
    "  ax0.set_yscale('log')\n",
    "  ax0.legend(loc='upper right', fontsize=16)\n",
    "\n",
    "  stack = []\n",
    "  for z in range(sample_size):\n",
    "      stack.append(to_rgb(out[z].permute(-2, -1,0).cpu().detach().numpy()))\n",
    "  ax1.imshow(np.clip(np.hstack(np.squeeze(stack)), 0,1))\n",
    "  ax1.axis('off')\n",
    "  plt.show()\n",
    "  print(i, loss.item(), flush = True)\n",
    "  return model_str_final"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "class ca_model_perception_clamp(nn.Module):\n",
    "    def __init__(self, checkpoint = None, seq_layers = None, device = 'cuda'):\n",
    "        '''\n",
    "        Kind of a modular class for a CA model\n",
    "        args:\n",
    "            checkpoint = 'path/to/model.pt'\n",
    "            seq_layers = nn.Sequential(your, pytorch, layers)\n",
    "            device = 'cuda' or 'cpu'\n",
    "        '''\n",
    "        super(ca_model_perception_clamp, self).__init__()\n",
    "\n",
    "        self.ident = torch.tensor([[0.0,0.0,0.0],[0.0,1.0,0.0],[0.0,0.0,0.0]]).to(device)\n",
    "        self.sobel_x = (torch.tensor([[-1.0,0.0,1.0],[-2.0,0.0,2.0],[-1.0,0.0,1.0]])/8.0).to(device)\n",
    "        self.lap = (torch.tensor([[1.0,2.0,1.0],[2.0,-12,2.0],[1.0,2.0,1.0]])/16.0).to(device)\n",
    "        \n",
    "        if seq_layers is not None:\n",
    "            self.model = seq_layers\n",
    "        else:\n",
    "            self.model = nn.Sequential(\n",
    "                nn.Conv2d(64, 256, kernel_size = 3,padding =1,  bias = True),  \n",
    "                nn.ReLU(),\n",
    "                nn.Conv2d(256, 256, kernel_size = 3,padding =1,  bias = True),  \n",
    "                nn.ReLU(),\n",
    "                nn.Conv2d(256, 16, kernel_size =  1, bias = True),\n",
    "            )\n",
    "            \n",
    "        '''\n",
    "        initial condition for \"do nothing\" behaviour:\n",
    "            * all biases should be zero\n",
    "            * the weights of the last layer should be zero\n",
    "        '''\n",
    "        for l in range(len(self.model)):\n",
    "            if isinstance(self.model[l], nn.Conv2d):\n",
    "                self.model[l].bias.data.fill_(0)\n",
    "                if l == len(self.model) -1:\n",
    "                    self.model[l].weight.data.fill_(0)\n",
    "\n",
    "        if checkpoint is not None:\n",
    "            self.load_state_dict(torch.load(checkpoint))\n",
    "\n",
    "        self.to(device= device)\n",
    "    \n",
    "    def perchannel_conv(self, x, filters):\n",
    "        '''filters: [filter_n, h, w]'''\n",
    "        b, ch, h, w = x.shape\n",
    "        y = x.reshape(b*ch, 1, h, w)\n",
    "        y = torch.nn.functional.pad(y, [1, 1, 1, 1], 'circular')\n",
    "        y = torch.nn.functional.conv2d(y, filters[:,None])\n",
    "        return y.reshape(b, -1, h, w)\n",
    "\n",
    "    def perception(self, x):\n",
    "        filters = torch.stack([self.ident, self.sobel_x, self.sobel_x.T, self.lap])\n",
    "        return self.perchannel_conv(x, filters)\n",
    "        \n",
    "    def normalize_grads(self):\n",
    "        '''\n",
    "        gradient normalization for constant step size and to avoid spikes \n",
    "        '''\n",
    "        for p in self.parameters():\n",
    "            p.grad.data = p.grad.data/(p.grad.data.norm()+1e-8)    \n",
    "            \n",
    "            \n",
    "    def get_alive_mask(self, x):\n",
    "        '''\n",
    "        looks for cells that have values over 0.1, \n",
    "        and allows only their adjacent cells to participate in growth\n",
    "        '''\n",
    "        alpha = x[:,1:2,:,:]\n",
    "        pooled = (F.max_pool2d(alpha, 3,1, padding =1 ) > 0.1).float()\n",
    "        return pooled\n",
    "    \n",
    "    def train_step(self, seed, target, target_loss_func, iters, current_epoch = 1000, masked_loss=False):\n",
    "        '''\n",
    "        a single training step for the model,\n",
    "        feel free to play around with different loss functions like L1 loss \n",
    "\n",
    "        the loss is calculated for only the first 4 channels of the output\n",
    "        '''\n",
    "        x = seed \n",
    "        for i in range(iters):\n",
    "            x, alive_mask, mask_diff =  self.forward(x,i, current_epoch)\n",
    "\n",
    "        # print(x[:,:4, :,:].shape, target.shape)\n",
    "        # batch_mean_rmse_per_pixel = torch.mean(torch.sqrt((x[:,:1, :,:] - target)**2),dim=0)\n",
    "        batch_mean_rmse_per_pixel = torch.mean(torch.sqrt((x[:,0, :,:] - target[:,0,:,:])**2),dim=0)\n",
    "\n",
    "        if masked_loss == True:\n",
    "            alive_mask_dilated = (F.max_pool2d(alive_mask[0], 3,1, padding =1 ) > 0.1).float()\n",
    "            # alive_mask_dilated = torch.from_numpy(binary_closing(alive_mask[0].cpu().numpy() > 0.1)).float().to('cuda')\n",
    "            target_loss  =  target_loss_func(x[:,:1, :,:] * alive_mask_dilated, target * alive_mask_dilated)  \n",
    "        else:\n",
    "            target_loss  =  target_loss_func(x[:,:2, :,:] * target[:,1:,...], target * target[:,1:,...]) # used to synthesize almost all nodules \n",
    "\n",
    "\n",
    "\n",
    "        loss = target_loss \n",
    "            \n",
    "        return loss, x, alive_mask.cpu().numpy(), mask_diff.cpu().numpy() #batch_mean_rmse_per_pixel.detach().cpu().numpy()\n",
    "\n",
    "    def forward(self, x, i, current_epoch):\n",
    "        '''\n",
    "        nice little forward function for the model\n",
    "        1. fetches an alive mask \n",
    "        2. generates another random mask of 0's and 1's \n",
    "        3. updates the input \n",
    "        4. applies alive mask \n",
    "        '''\n",
    "        mask_previous = alive_mask = (x[:,1:2,:,:] > 0.1).float()\n",
    "        if current_epoch < 100: \n",
    "          alive_mask = self.get_alive_mask(x)\n",
    "        else:\n",
    "          if i % 3 == 0:\n",
    "            alive_mask = self.get_alive_mask(x)\n",
    "          else:\n",
    "            # alive_mask = self.get_alive_mask(x)\n",
    "            alive_mask = (x[:,1:2,:,:] > 0.1).float()\n",
    "            \n",
    "        mask_diff = alive_mask - mask_previous\n",
    "        mask = torch.clamp(torch.round(torch.rand_like(x[:,:1,:,:])) , 0,1)        \n",
    "        y = self.perception(x)\n",
    "        mask_new_cells_clamped = torch.clip((1-mask_diff)+.19,0,1) #make sure this is only applied to the first channel\n",
    "        \n",
    "        mask_new_cells_clamped_ones = torch.ones_like(torch.squeeze(mask_new_cells_clamped))\n",
    "        mask_new_cells_clamped2 = torch.repeat_interleave(mask_new_cells_clamped,16,1)\n",
    "        for i in np.arange(1,16,1):\n",
    "          mask_new_cells_clamped2[:,i,:,:] = mask_new_cells_clamped_ones\n",
    "        \n",
    "        out = x + self.model(y)*mask*mask_new_cells_clamped2\n",
    "        out *= alive_mask\n",
    "        \n",
    "        return out, alive_mask, mask_diff"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "class ca_model_step_size(nn.Module):\n",
    "    def __init__(self, checkpoint = None, seq_layers = None, device = 'cuda', grow_on_k_iter=3, background_intensity=.19, step_size=1, scale_mask=1):\n",
    "        '''\n",
    "        Kind of a modular class for a CA model\n",
    "        args:\n",
    "            checkpoint = 'path/to/model.pt'\n",
    "            seq_layers = nn.Sequential(your, pytorch, layers)\n",
    "            device = 'cuda' or 'cpu'\n",
    "        '''\n",
    "        super(ca_model_step_size, self).__init__()\n",
    "\n",
    "        self.ident = torch.tensor([[0.0,0.0,0.0],[0.0,1.0,0.0],[0.0,0.0,0.0]]).to(device)\n",
    "        self.sobel_x = (torch.tensor([[-1.0,0.0,1.0],[-2.0,0.0,2.0],[-1.0,0.0,1.0]])/8.0).to(device)\n",
    "        self.lap = (torch.tensor([[1.0,2.0,1.0],[2.0,-12,2.0],[1.0,2.0,1.0]])/16.0).to(device)\n",
    "        self.grow_on_k_iter = grow_on_k_iter\n",
    "        self.background_intensity = background_intensity\n",
    "        self.step_size = step_size\n",
    "        self.scale_mask = scale_mask\n",
    "        \n",
    "        if seq_layers is not None:\n",
    "            self.model = seq_layers\n",
    "        else:\n",
    "            self.model = nn.Sequential(\n",
    "                nn.Conv2d(64, 256, kernel_size = 3,padding =1,  bias = True),  \n",
    "                nn.ReLU(),\n",
    "                nn.Conv2d(256, 256, kernel_size = 3,padding =1,  bias = True),  \n",
    "                nn.ReLU(),\n",
    "                nn.Conv2d(256, 16, kernel_size =  1, bias = True),\n",
    "            )\n",
    "            \n",
    "        '''\n",
    "        initial condition for \"do nothing\" behaviour:\n",
    "            * all biases should be zero\n",
    "            * the weights of the last layer should be zero\n",
    "        '''\n",
    "        for l in range(len(self.model)):\n",
    "            if isinstance(self.model[l], nn.Conv2d):\n",
    "                self.model[l].bias.data.fill_(0)\n",
    "                if l == len(self.model) -1:\n",
    "                    self.model[l].weight.data.fill_(0)\n",
    "\n",
    "        if checkpoint is not None:\n",
    "            self.load_state_dict(torch.load(checkpoint))\n",
    "\n",
    "        self.to(device= device)\n",
    "    \n",
    "    def perchannel_conv(self, x, filters):\n",
    "        '''filters: [filter_n, h, w]'''\n",
    "        b, ch, h, w = x.shape\n",
    "        y = x.reshape(b*ch, 1, h, w)\n",
    "        y = torch.nn.functional.pad(y, [1, 1, 1, 1], 'circular')\n",
    "        y = torch.nn.functional.conv2d(y, filters[:,None])\n",
    "        return y.reshape(b, -1, h, w)\n",
    "\n",
    "    def perception(self, x):\n",
    "        filters = torch.stack([self.ident, self.sobel_x, self.sobel_x.T, self.lap])\n",
    "        return self.perchannel_conv(x, filters)\n",
    "        \n",
    "    def normalize_grads(self):\n",
    "        '''\n",
    "        gradient normalization for constant step size and to avoid spikes \n",
    "        '''\n",
    "        for p in self.parameters():\n",
    "            p.grad.data = p.grad.data/(p.grad.data.norm()+1e-8)    \n",
    "            \n",
    "            \n",
    "    def get_alive_mask(self, x):\n",
    "        '''\n",
    "        looks for cells that have values over 0.1, \n",
    "        and allows only their adjacent cells to participate in growth\n",
    "        '''\n",
    "        alpha = x[:,1:2,:,:]\n",
    "        pooled = (F.max_pool2d(alpha, 3,1, padding =1 ) > 0.1).float()\n",
    "        return pooled\n",
    "    \n",
    "    def train_step(self, seed, target, target_loss_func, iters, current_epoch = 1000, masked_loss=False):\n",
    "        '''\n",
    "        a single training step for the model,\n",
    "        feel free to play around with different loss functions like L1 loss \n",
    "\n",
    "        the loss is calculated for only the first 4 channels of the output\n",
    "        '''\n",
    "        x = seed \n",
    "        for i in range(iters):\n",
    "            x, alive_mask, other_mask =  self.forward(x,i, current_epoch)\n",
    "\n",
    "        # print(x[:,:4, :,:].shape, target.shape)\n",
    "        # batch_mean_rmse_per_pixel = torch.mean(torch.sqrt((x[:,:1, :,:] - target)**2),dim=0)\n",
    "        batch_mean_rmse_per_pixel = torch.mean(torch.sqrt((x[:,0, :,:] - target[:,0,:,:])**2),dim=0)\n",
    "\n",
    "        if masked_loss == True:\n",
    "            alive_mask_dilated = (F.max_pool2d(alive_mask[0], 3,1, padding =1 ) > 0.1).float()\n",
    "            # alive_mask_dilated = torch.from_numpy(binary_closing(alive_mask[0].cpu().numpy() > 0.1)).float().to('cuda')\n",
    "            target_loss  =  target_loss_func(x[:,:1, :,:] * alive_mask_dilated, target * alive_mask_dilated)  \n",
    "        else:\n",
    "            target_loss  =  target_loss_func(x[:,:2, :,:] * target[:,1:,...], target * target[:,1:,...]) # used to synthesize almost all nodules \n",
    "\n",
    "\n",
    "\n",
    "        loss = target_loss \n",
    "            \n",
    "        return loss, x, alive_mask.cpu().numpy(), other_mask.cpu().numpy() #batch_mean_rmse_per_pixel.detach().cpu().numpy()\n",
    "\n",
    "    def forward(self, x, i, current_epoch):\n",
    "        '''\n",
    "        nice little forward function for the model\n",
    "        1. fetches an alive mask \n",
    "        2. generates another random mask of 0's and 1's \n",
    "        3. updates the input \n",
    "        4. applies alive mask \n",
    "        '''\n",
    "        mask_previous = alive_mask = (x[:,1:2,:,:] > 0.1).float()\n",
    "        if current_epoch < 100: \n",
    "          alive_mask = self.get_alive_mask(x)\n",
    "        else:\n",
    "          if i % self.grow_on_k_iter == 0:\n",
    "            alive_mask = self.get_alive_mask(x)\n",
    "          else:\n",
    "            alive_mask = (x[:,1:2,:,:] > 0.1).float()\n",
    "        \n",
    "        mask_diff = alive_mask - mask_previous\n",
    "        mask_new_cells_clamped = torch.clip((1-mask_diff) + self.background_intensity,0,self.step_size) #make sure this is only applied to the first channel\n",
    "        \n",
    "        mask_new_cells_clamped_ones = torch.ones_like(torch.squeeze(mask_new_cells_clamped))*self.scale_mask\n",
    "        mask_new_cells_clamped2 = torch.repeat_interleave(mask_new_cells_clamped,16,1)\n",
    "        for idx_channel in np.arange(1,16,1):\n",
    "          mask_new_cells_clamped2[:,idx_channel,:,:] = mask_new_cells_clamped_ones\n",
    "        \n",
    "        mask = torch.clamp(torch.round(torch.rand_like(x[:,:1,:,:])) , 0,1) # original mask used\n",
    "        y = self.perception(x)\n",
    "        out = x + self.model(y)*mask*mask_new_cells_clamped2\n",
    "        out *= alive_mask\n",
    "        \n",
    "        return out, alive_mask, mask_new_cells_clamped2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "class CeA_00(nn.Module):\n",
    "    def __init__(self, checkpoint = None, seq_layers = None, device = 'cuda', grow_on_k_iter=3, background_intensity=.19, step_size=1, scale_mask=1, pretrain_thres=100):\n",
    "        '''\n",
    "        Kind of a modular class for a CA model\n",
    "        args:\n",
    "            checkpoint = 'path/to/model.pt'\n",
    "            seq_layers = nn.Sequential(your, pytorch, layers)\n",
    "            device = 'cuda' or 'cpu'\n",
    "        '''\n",
    "        super(CeA_00, self).__init__()\n",
    "\n",
    "        self.ident = torch.tensor([[0.0,0.0,0.0],[0.0,1.0,0.0],[0.0,0.0,0.0]]).to(device)\n",
    "        self.sobel_x = (torch.tensor([[-1.0,0.0,1.0],[-2.0,0.0,2.0],[-1.0,0.0,1.0]])/8.0).to(device)\n",
    "        self.lap = (torch.tensor([[1.0,2.0,1.0],[2.0,-12,2.0],[1.0,2.0,1.0]])/16.0).to(device)\n",
    "        self.grow_on_k_iter = grow_on_k_iter\n",
    "        self.background_intensity = background_intensity\n",
    "        self.step_size = step_size\n",
    "        self.scale_mask = scale_mask\n",
    "        self.pretrain_thres = pretrain_thres \n",
    "        \n",
    "        if seq_layers is not None:\n",
    "            self.model = seq_layers\n",
    "        else:\n",
    "            self.model = nn.Sequential(\n",
    "                nn.Conv2d(64, 256, kernel_size = 3,padding =1,  bias = True),  \n",
    "                nn.ReLU(),\n",
    "                nn.Conv2d(256, 256, kernel_size = 3,padding =1,  bias = True),  \n",
    "                nn.ReLU(),\n",
    "                nn.Conv2d(256, 16, kernel_size =  1, bias = True),\n",
    "            )\n",
    "            \n",
    "        '''\n",
    "        initial condition for \"do nothing\" behaviour:\n",
    "            * all biases should be zero\n",
    "            * the weights of the last layer should be zero\n",
    "        '''\n",
    "        for l in range(len(self.model)):\n",
    "            if isinstance(self.model[l], nn.Conv2d):\n",
    "                self.model[l].bias.data.fill_(0)\n",
    "                if l == len(self.model) -1:\n",
    "                    self.model[l].weight.data.fill_(0)\n",
    "\n",
    "        if checkpoint is not None:\n",
    "            self.load_state_dict(torch.load(checkpoint))\n",
    "\n",
    "        self.to(device= device)\n",
    "    \n",
    "    def perchannel_conv(self, x, filters):\n",
    "        '''filters: [filter_n, h, w]'''\n",
    "        b, ch, h, w = x.shape\n",
    "        y = x.reshape(b*ch, 1, h, w)\n",
    "        y = torch.nn.functional.pad(y, [1, 1, 1, 1], 'circular')\n",
    "        y = torch.nn.functional.conv2d(y, filters[:,None])\n",
    "        return y.reshape(b, -1, h, w)\n",
    "\n",
    "    def perception(self, x):\n",
    "        filters = torch.stack([self.ident, self.sobel_x, self.sobel_x.T, self.lap])\n",
    "        return self.perchannel_conv(x, filters)\n",
    "        \n",
    "    def normalize_grads(self):\n",
    "        '''\n",
    "        gradient normalization for constant step size and to avoid spikes \n",
    "        '''\n",
    "        for p in self.parameters():\n",
    "            p.grad.data = p.grad.data/(p.grad.data.norm()+1e-8)    \n",
    "            \n",
    "            \n",
    "    def get_alive_mask(self, x):\n",
    "        '''\n",
    "        looks for cells that have values over 0.1, \n",
    "        and allows only their adjacent cells to participate in growth\n",
    "        '''\n",
    "        alpha = x[:,1:2,:,:]\n",
    "        pooled = (F.max_pool2d(alpha, 3,1, padding =1 ) > 0.1).float()\n",
    "        return pooled\n",
    "    \n",
    "    def train_step(self, seed, target, target_loss_func, epochs_inside, epoch_outside = 1000, masked_loss=False):\n",
    "        '''\n",
    "        a single training step for the model,\n",
    "        feel free to play around with different loss functions like L1 loss \n",
    "\n",
    "        the loss is calculated for only the first 4 channels of the output\n",
    "        '''\n",
    "        x = seed \n",
    "        for epoch_in in range(epochs_inside):\n",
    "            x, alive_mask, other =  self.forward(x, epoch_in, epoch_outside)\n",
    "\n",
    "        if masked_loss == True:\n",
    "            alive_mask_dilated = (F.max_pool2d(alive_mask[0], 3,1, padding =1 ) > 0.1).float()\n",
    "            target_loss  =  target_loss_func(x[:,:1, :,:] * alive_mask_dilated, target * alive_mask_dilated)  \n",
    "        else:\n",
    "            target_loss  =  target_loss_func(x[:,:2, :,:] * target[:,1:,...], target * target[:,1:,...]) # used to synthesize almost all nodules \n",
    "        # target_loss  =  target_loss_func(x[:,:2, :,:], target) # ORIGINAL\n",
    "\n",
    "        loss = target_loss \n",
    "            \n",
    "        return loss, x, alive_mask.cpu().numpy(), other.detach().cpu().numpy() #batch_mean_rmse_per_pixel.detach().cpu().numpy()\n",
    "\n",
    "    def forward(self, x, epoch_in, epoch_outside):\n",
    "        '''\n",
    "        nice little forward function for the model\n",
    "        1. fetches an alive mask \n",
    "        2. generates another random mask of 0's and 1's \n",
    "        3. updates the input \n",
    "        4. applies alive mask \n",
    "        '''\n",
    "        mask_previous = alive_mask = (x[:,1:2,:,:] > 0.1).float()\n",
    "        # self_pretraining\n",
    "        if epoch_outside < self.pretrain_thres: \n",
    "          alive_mask = self.get_alive_mask(x)\n",
    "        else:\n",
    "          if epoch_in % self.grow_on_k_iter == 0:\n",
    "            alive_mask = self.get_alive_mask(x)\n",
    "          else:\n",
    "            alive_mask = (x[:,1:2,:,:] > 0.1).float()\n",
    "            mask_previous = torch.zeros_like(alive_mask)#OMM added in CeA\n",
    "\n",
    "        # MASK CLAMP     \n",
    "        # | = self.background_intensity  \n",
    "        # X = self.step_size\n",
    "        # S = self.scale_mask\n",
    "        # ch0            ch1           ch2           ...\n",
    "        # |||||||||||||| SSSSSSSSSSSSS SSSSSSSSSSSSS SSSSSSSSSSSSS\n",
    "        # |||||XXXX||||| SSSSSSSSSSSSS SSSSSSSSSSSSS SSSSSSSSSSSSS\n",
    "        # |||XX||||XX||| SSSSSSSSSSSSS SSSSSSSSSSSSS SSSSSSSSSSSSS\n",
    "        # ||XX||||||XX|| SSSSSSSSSSSSS SSSSSSSSSSSSS SSSSSSSSSSSSS\n",
    "        # |||XX||||XX||| SSSSSSSSSSSSS SSSSSSSSSSSSS SSSSSSSSSSSSS\n",
    "        # |||||XXXX||||| SSSSSSSSSSSSS SSSSSSSSSSSSS SSSSSSSSSSSSS\n",
    "        # |||||||||||||| SSSSSSSSSSSSS SSSSSSSSSSSSS SSSSSSSSSSSSS\n",
    "\n",
    "        mask_diff = alive_mask - mask_previous\n",
    "        mask_clamp_ch0 = torch.clip((1-mask_diff) + self.background_intensity,0,self.step_size) #make sure this is only applied to the first channel\n",
    "        mask_clamp = torch.repeat_interleave(mask_clamp_ch0,16,1)\n",
    "        mask_clamp_ones = torch.ones_like(torch.squeeze(mask_clamp_ch0))*self.scale_mask\n",
    "        for idx_channel in np.arange(1,16,1):\n",
    "          mask_clamp[:,idx_channel,:,:] = mask_clamp_ones\n",
    "\n",
    "        \n",
    "        mask = torch.clamp(torch.round(torch.rand_like(x[:,:1,:,:])) , 0,1)        \n",
    "        P = self.perception(x)\n",
    "        Y = self.model(P)\n",
    "        out = x + (Y * mask * mask_clamp)  \n",
    "        out *= alive_mask\n",
    "        \n",
    "        return out, alive_mask, mask_clamp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# #export\n",
    "# def sobel_reg(x, THRESHOLD_LIM=0.01):\n",
    "#   sobel_reg = gradient_filter(x[:,:1,...])\n",
    "#   sobel_reg_sum = torch.sum(sobel_reg)\n",
    "#   sobel_reg_cells_larger_than_thres = len(torch.where(sobel_reg > THRESHOLD_LIM)[0])\n",
    "#   sobel_reg_sum_average = sobel_reg_sum/sobel_reg_cells_larger_than_thres\n",
    "#   if sobel_reg_cells_larger_than_thres == 0: # if there is all zeros return 0\n",
    "#     sobel_reg_sum_average = 0\n",
    "#   return sobel_reg_sum_average"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "class ca_model_laplacian_regularizer(nn.Module):\n",
    "    def __init__(self, checkpoint = None, seq_layers = None, device = 'cuda', grow_on_k_iter=3, background_intensity=.19, step_size=1, scale_mask=1, reg1=1):\n",
    "        '''\n",
    "        Kind of a modular class for a CA model\n",
    "        args:\n",
    "            checkpoint = 'path/to/model.pt'\n",
    "            seq_layers = nn.Sequential(your, pytorch, layers)\n",
    "            device = 'cuda' or 'cpu'\n",
    "        '''\n",
    "        super(ca_model_laplacian_regularizer, self).__init__()\n",
    "\n",
    "        self.ident = torch.tensor([[0.0,0.0,0.0],[0.0,1.0,0.0],[0.0,0.0,0.0]]).to(device)\n",
    "        self.sobel_x = (torch.tensor([[-1.0,0.0,1.0],[-2.0,0.0,2.0],[-1.0,0.0,1.0]])/8.0).to(device)\n",
    "        self.lap = (torch.tensor([[1.0,2.0,1.0],[2.0,-12,2.0],[1.0,2.0,1.0]])/16.0).to(device)\n",
    "        self.grow_on_k_iter = grow_on_k_iter\n",
    "        self.background_intensity = background_intensity\n",
    "        self.step_size = step_size\n",
    "        self.scale_mask = scale_mask\n",
    "        self.reg1 = reg1\n",
    "        \n",
    "        if seq_layers is not None:\n",
    "            self.model = seq_layers\n",
    "        else:\n",
    "            self.model = nn.Sequential(\n",
    "                nn.Conv2d(64, 256, kernel_size = 3,padding =1,  bias = True),  \n",
    "                nn.ReLU(),\n",
    "                nn.Conv2d(256, 256, kernel_size = 3,padding =1,  bias = True),  \n",
    "                nn.ReLU(),\n",
    "                nn.Conv2d(256, 16, kernel_size =  1, bias = True),\n",
    "            )\n",
    "            \n",
    "        '''\n",
    "        initial condition for \"do nothing\" behaviour:\n",
    "            * all biases should be zero\n",
    "            * the weights of the last layer should be zero\n",
    "        '''\n",
    "        for l in range(len(self.model)):\n",
    "            if isinstance(self.model[l], nn.Conv2d):\n",
    "                self.model[l].bias.data.fill_(0)\n",
    "                if l == len(self.model) -1:\n",
    "                    self.model[l].weight.data.fill_(0)\n",
    "\n",
    "        if checkpoint is not None:\n",
    "            self.load_state_dict(torch.load(checkpoint))\n",
    "\n",
    "        self.to(device= device)\n",
    "    \n",
    "    def perchannel_conv(self, x, filters):\n",
    "        '''filters: [filter_n, h, w]'''\n",
    "        b, ch, h, w = x.shape\n",
    "        y = x.reshape(b*ch, 1, h, w)\n",
    "        y = torch.nn.functional.pad(y, [1, 1, 1, 1], 'circular')\n",
    "        y = torch.nn.functional.conv2d(y, filters[:,None])\n",
    "        return y.reshape(b, -1, h, w)\n",
    "\n",
    "    def perception(self, x):\n",
    "        filters = torch.stack([self.ident, self.sobel_x, self.sobel_x.T, self.lap])\n",
    "        return self.perchannel_conv(x, filters)\n",
    "        \n",
    "    def normalize_grads(self):\n",
    "        '''\n",
    "        gradient normalization for constant step size and to avoid spikes \n",
    "        '''\n",
    "        for p in self.parameters():\n",
    "            p.grad.data = p.grad.data/(p.grad.data.norm()+1e-8)    \n",
    "            \n",
    "            \n",
    "    def get_alive_mask(self, x):\n",
    "        '''\n",
    "        looks for cells that have values over 0.1, \n",
    "        and allows only their adjacent cells to participate in growth\n",
    "        '''\n",
    "        alpha = x[:,1:2,:,:]\n",
    "        pooled = (F.max_pool2d(alpha, 3,1, padding =1 ) > 0.1).float()\n",
    "        return pooled\n",
    "    \n",
    "    def train_step(self, seed, target, target_loss_func, epochs_inside, epoch_outside = 1000, masked_loss=False):\n",
    "        '''\n",
    "        a single training step for the model,\n",
    "        feel free to play around with different loss functions like L1 loss \n",
    "\n",
    "        the loss is calculated for only the first 4 channels of the output\n",
    "        '''\n",
    "        x = seed \n",
    "        for epoch_in in range(epochs_inside):\n",
    "            x, alive_mask, other_mask =  self.forward(x, epoch_in, epoch_outside)\n",
    "\n",
    "        # print(x[:,:4, :,:].shape, target.shape)\n",
    "        # batch_mean_rmse_per_pixel = torch.mean(torch.sqrt((x[:,:1, :,:] - target)**2),dim=0)\n",
    "        batch_mean_rmse_per_pixel = torch.mean(torch.sqrt((x[:,0, :,:] - target[:,0,:,:])**2),dim=0)\n",
    "\n",
    "        if masked_loss == True:\n",
    "            alive_mask_dilated = (F.max_pool2d(alive_mask[0], 3,1, padding =1 ) > 0.1).float()\n",
    "            # alive_mask_dilated = torch.from_numpy(binary_closing(alive_mask[0].cpu().numpy() > 0.1)).float().to('cuda')\n",
    "            target_loss  =  target_loss_func(x[:,:1, :,:] * alive_mask_dilated, target * alive_mask_dilated)  \n",
    "        else:\n",
    "            target_loss  =  target_loss_func(x[:,:2, :,:] * target[:,1:,...], target * target[:,1:,...]) # used to synthesize almost all nodules \n",
    "\n",
    "        sobel_regularizer = sobel_reg(x)\n",
    "        # print(f'   out(x)={x.shape}, sobel_regularizer={sobel_regularizer}')\n",
    "\n",
    "        loss = target_loss + (sobel_regularizer*self.reg1)\n",
    "            \n",
    "        return loss, x, alive_mask.cpu().numpy(), other_mask.cpu().numpy() #batch_mean_rmse_per_pixel.detach().cpu().numpy()\n",
    "\n",
    "    def forward(self, x, epoch_in, epoch_outside):\n",
    "        '''\n",
    "        nice little forward function for the model\n",
    "        1. fetches an alive mask \n",
    "        2. generates another random mask of 0's and 1's \n",
    "        3. updates the input \n",
    "        4. applies alive mask \n",
    "        '''\n",
    "        mask_previous = alive_mask = (x[:,1:2,:,:] > 0.1).float()\n",
    "        mode = 0\n",
    "        if epoch_outside < 100: \n",
    "          alive_mask = self.get_alive_mask(x)\n",
    "          mode = 1\n",
    "        else:\n",
    "          if epoch_in % self.grow_on_k_iter == 0:\n",
    "            alive_mask = self.get_alive_mask(x)\n",
    "            mode = 2\n",
    "          else:\n",
    "            alive_mask = (x[:,1:2,:,:] > 0.1).float()\n",
    "            mode = 3\n",
    "        \n",
    "        mask_diff = alive_mask - mask_previous\n",
    "        mask_new_cells_clamped = torch.clip((1-mask_diff) + self.background_intensity,0,self.step_size) #make sure this is only applied to the first channel\n",
    "        \n",
    "        mask_new_cells_clamped_ones = torch.ones_like(torch.squeeze(mask_new_cells_clamped))*self.scale_mask\n",
    "        mask_new_cells_clamped2 = torch.repeat_interleave(mask_new_cells_clamped,16,1)\n",
    "        for idx_channel in np.arange(1,16,1):\n",
    "          mask_new_cells_clamped2[:,idx_channel,:,:] = mask_new_cells_clamped_ones\n",
    "        \n",
    "        mask = torch.clamp(torch.round(torch.rand_like(x[:,:1,:,:])) , 0,1) # original mask used\n",
    "        y = self.perception(x)\n",
    "        out = x + self.model(y)*mask*mask_new_cells_clamped2\n",
    "        out *= alive_mask\n",
    "        # print(f'({epoch_in}) ({mode})  y={y.shape} alive_mask={alive_mask.shape} out={out.shape}')\n",
    "        \n",
    "        return out, alive_mask, mask_new_cells_clamped2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "class ca_model_l2reg(nn.Module):\n",
    "    def __init__(self, checkpoint = None, seq_layers = None, device = 'cuda', grow_on_k_iter=3, background_intensity=.19, step_size=1, scale_mask=1, l2reg=0):\n",
    "        '''\n",
    "        Kind of a modular class for a CA model\n",
    "        args:\n",
    "            checkpoint = 'path/to/model.pt'\n",
    "            seq_layers = nn.Sequential(your, pytorch, layers)\n",
    "            device = 'cuda' or 'cpu'\n",
    "        '''\n",
    "        super(ca_model_l2reg, self).__init__()\n",
    "\n",
    "        self.ident = torch.tensor([[0.0,0.0,0.0],[0.0,1.0,0.0],[0.0,0.0,0.0]]).to(device)\n",
    "        self.sobel_x = (torch.tensor([[-1.0,0.0,1.0],[-2.0,0.0,2.0],[-1.0,0.0,1.0]])/8.0).to(device)\n",
    "        self.lap = (torch.tensor([[1.0,2.0,1.0],[2.0,-12,2.0],[1.0,2.0,1.0]])/16.0).to(device)\n",
    "        self.grow_on_k_iter = grow_on_k_iter\n",
    "        self.background_intensity = background_intensity\n",
    "        self.step_size = step_size\n",
    "        self.scale_mask = scale_mask\n",
    "        self.l2reg = l2reg\n",
    "        \n",
    "        if seq_layers is not None:\n",
    "            self.model = seq_layers\n",
    "        else:\n",
    "            self.model = nn.Sequential(\n",
    "                nn.Conv2d(64, 256, kernel_size = 3,padding =1,  bias = True),  \n",
    "                nn.ReLU(),\n",
    "                nn.Conv2d(256, 256, kernel_size = 3,padding =1,  bias = True),  \n",
    "                nn.ReLU(),\n",
    "                nn.Conv2d(256, 16, kernel_size =  1, bias = True),\n",
    "            )\n",
    "            \n",
    "        '''\n",
    "        initial condition for \"do nothing\" behaviour:\n",
    "            * all biases should be zero\n",
    "            * the weights of the last layer should be zero\n",
    "        '''\n",
    "        for l in range(len(self.model)):\n",
    "            if isinstance(self.model[l], nn.Conv2d):\n",
    "                self.model[l].bias.data.fill_(0)\n",
    "                if l == len(self.model) -1:\n",
    "                    self.model[l].weight.data.fill_(0)\n",
    "\n",
    "        if checkpoint is not None:\n",
    "            self.load_state_dict(torch.load(checkpoint))\n",
    "\n",
    "        self.to(device= device)\n",
    "    \n",
    "    def perchannel_conv(self, x, filters):\n",
    "        '''filters: [filter_n, h, w]'''\n",
    "        b, ch, h, w = x.shape\n",
    "        y = x.reshape(b*ch, 1, h, w)\n",
    "        y = torch.nn.functional.pad(y, [1, 1, 1, 1], 'circular')\n",
    "        y = torch.nn.functional.conv2d(y, filters[:,None])\n",
    "        return y.reshape(b, -1, h, w)\n",
    "\n",
    "    def perception(self, x):\n",
    "        filters = torch.stack([self.ident, self.sobel_x, self.sobel_x.T, self.lap])\n",
    "        return self.perchannel_conv(x, filters)\n",
    "        \n",
    "    def normalize_grads(self):\n",
    "        '''\n",
    "        gradient normalization for constant step size and to avoid spikes \n",
    "        '''\n",
    "        for p in self.parameters():\n",
    "            p.grad.data = p.grad.data/(p.grad.data.norm()+1e-8)    \n",
    "            \n",
    "            \n",
    "    def get_alive_mask(self, x):\n",
    "        '''\n",
    "        looks for cells that have values over 0.1, \n",
    "        and allows only their adjacent cells to participate in growth\n",
    "        '''\n",
    "        alpha = x[:,1:2,:,:]\n",
    "        pooled = (F.max_pool2d(alpha, 3,1, padding =1 ) > 0.1).float()\n",
    "        return pooled\n",
    "    \n",
    "    def train_step(self, seed, target, target_loss_func, epochs_inside, epoch_outside = 1000, masked_loss=False):\n",
    "        '''\n",
    "        a single training step for the model,\n",
    "        feel free to play around with different loss functions like L1 loss \n",
    "\n",
    "        the loss is calculated for only the first 4 channels of the output\n",
    "        '''\n",
    "        x = seed \n",
    "        for epoch_in in range(epochs_inside):\n",
    "            x, alive_mask, Y =  self.forward(x, epoch_in, epoch_outside)\n",
    "\n",
    "        # print(x[:,:4, :,:].shape, target.shape)\n",
    "        # batch_mean_rmse_per_pixel = torch.mean(torch.sqrt((x[:,:1, :,:] - target)**2),dim=0)\n",
    "        batch_mean_rmse_per_pixel = torch.mean(torch.sqrt((x[:,0, :,:] - target[:,0,:,:])**2),dim=0)\n",
    "\n",
    "        if masked_loss == True:\n",
    "            alive_mask_dilated = (F.max_pool2d(alive_mask[0], 3,1, padding =1 ) > 0.1).float()\n",
    "            # alive_mask_dilated = torch.from_numpy(binary_closing(alive_mask[0].cpu().numpy() > 0.1)).float().to('cuda')\n",
    "            target_loss  =  target_loss_func(x[:,:1, :,:] * alive_mask_dilated, target * alive_mask_dilated)  \n",
    "        else:\n",
    "            target_loss  =  target_loss_func(x[:,:2, :,:] * target[:,1:,...], target * target[:,1:,...]) # used to synthesize almost all nodules \n",
    "\n",
    "        loss_reg = torch.sum(torch.abs(Y[:,:1,...]))\n",
    "\n",
    "        loss = target_loss + (loss_reg*self.l2reg) \n",
    "            \n",
    "        return loss, x, alive_mask.cpu().numpy(), Y.detach().cpu().numpy() #batch_mean_rmse_per_pixel.detach().cpu().numpy()\n",
    "\n",
    "    def forward(self, x, epoch_in, epoch_outside):\n",
    "        '''\n",
    "        nice little forward function for the model\n",
    "        1. fetches an alive mask \n",
    "        2. generates another random mask of 0's and 1's \n",
    "        3. updates the input \n",
    "        4. applies alive mask \n",
    "        '''\n",
    "        mask_previous = alive_mask = (x[:,1:2,:,:] > 0.1).float()\n",
    "        if epoch_outside < 100: \n",
    "          alive_mask = self.get_alive_mask(x)\n",
    "        else:\n",
    "          if epoch_in % self.grow_on_k_iter == 0:\n",
    "            alive_mask = self.get_alive_mask(x)\n",
    "          else:\n",
    "            alive_mask = (x[:,1:2,:,:] > 0.1).float()\n",
    "        \n",
    "        mask_diff = alive_mask - mask_previous\n",
    "        mask_new_cells_clamped = torch.clip((1-mask_diff) + self.background_intensity,0,self.step_size) #make sure this is only applied to the first channel\n",
    "        \n",
    "        mask_new_cells_clamped_ones = torch.ones_like(torch.squeeze(mask_new_cells_clamped))*self.scale_mask\n",
    "        mask_new_cells_clamped2 = torch.repeat_interleave(mask_new_cells_clamped,16,1)\n",
    "        for idx_channel in np.arange(1,16,1):\n",
    "          mask_new_cells_clamped2[:,idx_channel,:,:] = mask_new_cells_clamped_ones\n",
    "        \n",
    "        mask = torch.clamp(torch.round(torch.rand_like(x[:,:1,:,:])) , 0,1) # original mask used\n",
    "        P = self.perception(x)\n",
    "        Y = self.model(P)\n",
    "        out = x + Y *mask*mask_new_cells_clamped2\n",
    "        out *= alive_mask\n",
    "        \n",
    "        return out, alive_mask, Y #mask_new_cells_clamped2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
